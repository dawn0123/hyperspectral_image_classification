{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "windowSize = 5\n",
    "numPCAcomponents = 30\n",
    "testRatio = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the neccesary functions for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadIndianPinesData():\n",
    "    data_path = os.path.join(os.getcwd(),'data')\n",
    "    data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "    labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "def reports (X_test,y_test):\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "               ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "               'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "               'Stone-Steel-Towers']\n",
    "\n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy\n",
    "\n",
    "\n",
    "def applyPCA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, pca\n",
    "\n",
    "def Patch(data,height_index,width_index):\n",
    "    #transpose_array = data.transpose((2,0,1))\n",
    "    #print transpose_array.shape\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.load(\"/home/deeplearning/Desktop/GITHUB/XtestWindowSize\" \n",
    "                 + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRAtio\" + str(testRatio) + \".npy\")\n",
    "y_test = np.load(\"/home/deeplearning/Desktop/GITHUB/ytestWindowSize\" \n",
    "                 + str(windowSize) + \"PCA\" + str(numPCAcomponents) + \"testRatio\" + str(testRatio) + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test  = np.reshape(X_test, (X_test.shape[0], X_test.shape[3], X_test.shape[1], X_test.shape[2]))\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model architecture and weights\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy = reports(X_test,y_test)\n",
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = 'report' + \"WindowSize\" + str(windowSize) + \"PCA\" + str(numComponents) + \"testRatio\" + str(testRatio) +\".txt\"\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the original image\n",
    "X, y = loadIndianPinesData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,pca = applyPCA(X,numComponents=numComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = 5\n",
    "numComponents = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height-PATCH_SIZE+1):\n",
    "    for j in range(width-PATCH_SIZE+1):\n",
    "        target = int(y[i+PATCH_SIZE/2, j+PATCH_SIZE/2])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            #print (image_patch.shape)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[2],image_patch.shape[0],image_patch.shape[1]).astype('float32')                                   \n",
    "            prediction = (model.predict_classes(X_test_image))                         \n",
    "            outputs[i+PATCH_SIZE/2][j+PATCH_SIZE/2] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(5,5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
